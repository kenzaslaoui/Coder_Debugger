This is a generative AI project that uses LLMs to generate and debug code. 

I use the Deepseek Coder 6.7B intruct to generate code. The output of the model is then parsed and the code generated is executed. If it is correct, the output of the base DS Coder is returned. However, if it fails, debugging is initiated using a finetuned version of Deepseek Coder 6.7B intruct. The code generated by the debugger is also executed to check for correctness. This entire process is orchestrated by a coordinator which uses langchain and GPT-4o-mini. 

I finetuned the debugging model (Deepseek Coder 6.7B intruct) using quantized LoRA. The finetuning process was done on Google Colab due to resource constraints.

Most of the files in this project were generated from jupyter notebooks as I needed to use google colab for both training and inference.

I could not push the finetuned model to github due to resource constraints. However, you can access it through this link: 
https://drive.google.com/drive/folders/1Uh1uj1Ih4L3GWQ2Bk1pVDm0e_wDxjNU1?usp=sharing

This is still work in progress!

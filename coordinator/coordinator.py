# -*- coding: utf-8 -*-
"""Copy of coordinator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cY_xNogeloM-E8pyV4RNvc2pcfE9Jjuz
"""

!pip install langchain openai
!pip install --upgrade langchain langchain-community openai

import warnings
warnings.filterwarnings("ignore")

import pprint
from google.colab import userdata
import openai
import os
import sys
import importlib.util
from langchain_community.chat_models import ChatOpenAI
from langchain_core.messages import HumanMessage
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
openai.api_key = userdata.get('OPENAI_API_KEY')
os.environ['OPENAI_API_KEY'] = openai.api_key


class Coordinator:
    def __init__(self):
        base_path = "/content/drive/MyDrive/Academic_Professional_Planning/SPRING2025/GEN_AI/Multi_Agent_Self_Debugger_Coder/agents"

        def load_class(module_name, file_path, class_name):
            spec = importlib.util.spec_from_file_location(module_name, file_path)
            mod = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(mod)
            return getattr(mod, class_name)

        CodeGenerator = load_class("generator", f"{base_path}/generator.py", "CodeGenerator")
        ExecutionManager = load_class("executor", f"{base_path}/executor.py", "CodeExecutor")
        CodeDebugger = load_class("debugger", f"{base_path}/debugger.py", "CodeDebugger")

        self.generator = CodeGenerator()
        self.executor = ExecutionManager()
        self.debugger = CodeDebugger()
        self.parser_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    def parse_code_from_output(self, full_output: str) -> str:
        """Uses GPT-4o-mini to extract just the code from the LLM's full response."""
        parse_prompt = (
            "You are a helpful assistant that extracts only the raw Python code "
            "from a mixed natural language and code response. "
            "Please return only the raw Python code without any quotes, triple quotes, or other string delimiters. Do not include any extra explanation or markdown. Just the plain code."
            f"Input:\n{full_output}"
        )
        response = self.parser_llm([HumanMessage(content=parse_prompt)])
        return response.content.strip()

    def run_pipeline(self, task: str, test_cases: list[str]):

        # Prompt (Task + test cases)
        prompt = f"Task:\n{task}\nExample Test Cases:\n" + "\n".join(test_cases)

        # Generate full output (task, code, explanation)
        generator_full_output = self.generator.generate_code(task, test_cases)
        print(f"Generator's output:\n{generator_full_output}")

        # Extract just the code with the gpt 4 llm
        generator_code = self.parse_code_from_output(generator_full_output)
        if not generator_code.strip():
            raise ValueError("Parsed generator code is empty. Check generator output format.")
        print(f"\n\nParsed generator's code:\n{generator_code}")

        # Execute the generator's code and evaluate
        generator_result = self.executor.run_code(generator_code, test_cases)
        if generator_result["success"]:
            print(f"\n\nExecution of generator's code successful!")
            final_output = {
                "generator's code": generator_code,
                "success": True,
                "stdout": generator_result["stdout"]
            }
            return pprint.pprint(final_output)

        # Debug if failed
        print(f"\n\nExecution of generator's code failed. Invoking debugger.")
        generator_error_msg = (
                   f"STDERR:\n{generator_result['stderr']}\n\nSTDOUT:\n{generator_result['stdout']}"
        )
        print(f"\n\nGenerator's error message:\n{generator_error_msg}")

        debugger_output = self.debugger.debug_code(prompt, generator_code, generator_error_msg)

        print(f"\n\nDebugger's Generated output:\n{debugger_output}")

        # Extract just the code with the gpt 4 llm
        fixed_code = self.parse_code_from_output(debugger_output)
        if not fixed_code.strip():
            raise ValueError("Parsed debugger's code is empty. Check debugger's output format.")
        print(f"\n\nParsed debugger's code:\n{fixed_code}")

        # Execute the debugger's code and evaluate
        debugger_result = self.executor.run_code(fixed_code, test_cases)
        if debugger_result["success"]:
            print("Execution of debugger's code successful!")
            final_output = {
                "generator's code": generator_code,
                "generator's success": False,
                "debugger's code": fixed_code,
                "debugger's success": True,
                "stdout": debugger_result["stdout"]
            }
            return pprint.pprint(final_output)

        print(f"\n\nExecution of debugger code failed. Try again later!")
        debug_error_msg = (
            f"STDERR:\n{generator_result['stderr']}\n\nSTDOUT:\n{generator_result['stdout']}"
        )
        final_output = {
            "generator's code": generator_code,
            "generator's success": False,
            "debugger's code": fixed_code,
            "debugger's success": False,
            "error": debug_error_msg
        }
        return pprint.pprint(final_output)